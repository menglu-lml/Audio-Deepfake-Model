# Audio-Deepfake-Model
Version 1: the initial prototype of **End-to-End** model

# Network Structure
![End-to-end_v2](https://user-images.githubusercontent.com/114956483/193681934-b168f174-17b7-4d43-8a90-cdda28270b8e.jpg)
The raw audio are fed into the upper path of model (pink path), and receive a classification label from the SincNet-transformer structure. Independently, the ENF signal feature of the real audio are extracted to train the one-class SVM (Purple path). 

If the SincNet-transformer classifies an input audio as a fake data, then this audio will be considered as a Deepfake. For those audios, which received a label of real from the SincNet-transformer, will be passed into the trained SVM to be evaluated again and the SVM will give them a final classification result.

# Experiment
Currently, the ADD dataset is used for testing.

Track 1: **Fully fake** audios generated using the TTS and VC algorithms with various background noises

Track 2: **Partially fake** speech generated by manipulating the original real utterances with real or synthesized audios

| Tables                      | Track 1       |          Track 2          |
| --------------------------- |:-------------:| -------------------------:|
| SincNet-Transformer only    |      9%       |           73.09%          |
| SincNet-Transformer + ENF   |     18.35%    |           41.49%          |


The current experiment result indicates that the ENF componnets may only be effective for the case of partial deepfake detection. We will continuing to focus on and improve the ENF part. 
