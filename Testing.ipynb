{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41d9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/menglu/123/Deepfake\")) #need to change the path\n",
    "from extract_enf import extract_enf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import glob\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "import collections\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import librosa, librosa.display\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import yaml\n",
    "import copy\n",
    "from scipy import signal\n",
    "import wave\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select if want to include ENF feature in the model\n",
    "need_ENF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (need_ENF) == True:\n",
    "    \"extract the ENF signal of real data and train the SVM\"\n",
    "    ENFVec = []\n",
    "    for file in glob.glob(f\"/home/menglu/123/Dataset/ADD2022/ADD_train_dev/real/*.wav\"):  # only use real data to train the SVM\n",
    "        sig, sample_rate = librosa.load(file,sr=16000)   \n",
    "        mysignal = pyENF(signal0=sig, fs=1000, nominal=50, \n",
    "                                         harmonic_multiples=1,\n",
    "                                         duration=0.05, strip_index=0)\n",
    "        spectro_strip, frequency_support = mysignal.compute_spectrogam_strips()\n",
    "        weights = mysignal.compute_combining_weights_from_harmonics()\n",
    "        OurStripCell, initial_frequency = mysignal.compute_combined_spectrum(spectro_strip, weights, frequency_support)\n",
    "        ENF = mysignal.compute_ENF_from_combined_strip(spectro_strip, initial_frequency)\n",
    "        if len(ENF)>=200:  # we only use the real training data that have an ENF vector longer than 200\n",
    "            ENF = ENF[:200]\n",
    "            enf_of_one_sample = [subitem for item in ENF for subitem in item]\n",
    "            ENFVec.append(enf_of_one_sample)\n",
    "            \n",
    "    # train the ONE-CLASS SVM using real data only\n",
    "    clf = svm.OneClassSVM(nu=0.5, kernel=\"sigmoid\", gamma='scale')\n",
    "    clf.fit(ENFVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bdad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1474e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Loading Testing dataset ############\n",
    "\n",
    "AudioFile = collections.namedtuple('AudioFile',\n",
    "    ['file_name','path','label', 'key'])\n",
    "\n",
    "class ADDDataset(Dataset):\n",
    "    def __init__(self, data_path=None, label_path=None,transform=None,\n",
    "                 is_train=True,is_eval=False,feature=None,track=None):\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "        self.track = track\n",
    "        self.feature = feature\n",
    "        \n",
    "        self.dset_name = 'eval' if is_eval else 'train' if is_train else 'dev'\n",
    "        cache_fname = 'cache_ADD_{}_{}.npy'.format(self.dset_name,self.track)\n",
    "        if (self.dset_name == 'eval'):\n",
    "            cache_fname = 'cache_ADD_{}_{}.npy'.format(self.dset_name,self.track)\n",
    "            self.cache_fname = os.path.join(\"/home/menglu/123/Deepfake/built\", cache_fname) #need to change the directory\n",
    "        else:   \n",
    "            cache_fname = 'cache_ADD_{}.npy'.format(self.dset_name)\n",
    "            self.cache_fname = os.path.join(\"/home/menglu/123/Deepfake/built\", cache_fname)\n",
    "  \n",
    "        if os.path.exists(self.cache_fname):\n",
    "            self.data_x, self.data_y, self.files_meta = torch.load(self.cache_fname)\n",
    "            print('Dataset loaded from cache', self.cache_fname)\n",
    "        else: \n",
    "            self.files_meta = self.parse_protocols_file(self.label_path)\n",
    "            data = list(map(self.read_file, self.files_meta))\n",
    "            self.data_x, self.data_y= map(list, zip(*data))\n",
    "            if self.transform:\n",
    "                self.data_x = Parallel(n_jobs=5, prefer='threads')(delayed(self.transform)(x) for x in self.data_x)                          \n",
    "            torch.save((self.data_x, self.data_y, self.files_meta), self.cache_fname)\n",
    "        \n",
    "    def __len__(self):\n",
    "        self.length = len(self.data_x)\n",
    "        return self.length\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data_x[idx]\n",
    "        y = self.data_y[idx]\n",
    "        return x, y\n",
    "    \n",
    "    def read_file(self, meta):   \n",
    "        data_x, sample_rate = librosa.load(meta.path,sr=16000)       \n",
    "        data_y = meta.key\n",
    "        return data_x, float(data_y)\n",
    "      \n",
    "    def parse_line(self,line):\n",
    "        tokens = line.strip().split(' ')\n",
    "        audio_path=os.path.join(self.data_path, tokens[0]).replace('\\\\','/')\n",
    "        return AudioFile(file_name=tokens[0], path = audio_path,\n",
    "                         label=tokens[1], key=int(tokens[1] == 'genuine'))\n",
    "        \n",
    "    def parse_protocols_file(self, label_path):\n",
    "        lines = open(label_path).readlines()\n",
    "        files_meta = map(self.parse_line, lines)\n",
    "        return list(files_meta)\n",
    "\n",
    "    def __len__(self):\n",
    "        self.length = len(self.data_x)\n",
    "        return self.length\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data_x[idx]\n",
    "        y = self.data_y[idx]\n",
    "        return x, y\n",
    "    \n",
    "    def read_file(self, meta):   \n",
    "        data_x, sample_rate = librosa.load(meta.path,sr=16000)       \n",
    "        data_y = meta.key\n",
    "        return data_x, float(data_y)\n",
    "      \n",
    "    def parse_line(self,line):\n",
    "        tokens = line.strip().split(' ')\n",
    "        audio_path=os.path.join(self.data_path, tokens[0]).replace('\\\\','/')\n",
    "        return AudioFile(file_name=tokens[0], path = audio_path,\n",
    "                         label=tokens[1], key=int(tokens[1] == 'genuine'))\n",
    "        \n",
    "    def parse_protocols_file(self, label_path):\n",
    "        lines = open(label_path).readlines()\n",
    "        files_meta = map(self.parse_line, lines)\n",
    "        return list(files_meta)\n",
    "\n",
    "\n",
    "track = 'track1'\n",
    "database_path = \"/home/menglu/123/Dataset/ADD2022/\"+track+\"adp_out\"\n",
    "label_path = \"/home/menglu/123/Dataset/ADD2022/label/\"+track+\"_label.txt\"\n",
    "transform = transforms.Compose([\n",
    "    lambda x: pad(x),\n",
    "    lambda x: Tensor(x)])\n",
    "\n",
    "is_eval = True\n",
    "evl_set = ADDDataset(data_path=database_path,label_path=label_path,is_train=False, \n",
    "                      transform=transform, is_eval=is_eval, track=track)\n",
    "### test enf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d243f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(dataset, model, device, save_path, svm=None):\n",
    "    \"Function for testing process\"\n",
    "    \n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    num_correct = 0.0\n",
    "    num_total = 0.0\n",
    "    model.eval()\n",
    "    true_y = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch_x, batch_y in data_loader:\n",
    "        true_y.extend(batch_y.numpy())\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        batch_out = model(batch_x,batch_y,is_test=True)\n",
    "        batch_score = (batch_out[:, 1]\n",
    "                       ).data.cpu().numpy().ravel()\n",
    "        _, batch_pred = batch_out.max(dim=1)\n",
    "\n",
    "        if (svm != None) and (batch_pred == 1):\n",
    "            x = batch_x.cpu().detach().numpy()\n",
    "            ### extract ENF signal for this particular audio clip and classify this data again\n",
    "            mysignal = pyENF(signal0=x[0], fs=1000, nominal=50, \n",
    "                                         harmonic_multiples=1,\n",
    "                                         duration=0.05, strip_index=0)\n",
    "            spectro_strip, frequency_support = mysignal.compute_spectrogam_strips()\n",
    "            weights = mysignal.compute_combining_weights_from_harmonics()\n",
    "            OurStripCell, initial_frequency = mysignal.compute_combined_spectrum(spectro_strip, weights, frequency_support)\n",
    "            ENF = mysignal.compute_ENF_from_combined_strip(spectro_strip, initial_frequency)\n",
    "\n",
    "            if len(ENF)>=200:\n",
    "                ENF = ENF[:200]\n",
    "                new_ENF = [subitem for item in ENF for subitem in item]\n",
    "                prediction = svm.predict([new_ENF])\n",
    "                if prediction[0] == -1:\n",
    "                    batch_pred = Tensor([0]).cuda()\n",
    "                else:\n",
    "                    batch_pred = Tensor([1]).cuda()\n",
    "                    \n",
    "        num_correct += (batch_pred == batch_y).sum(dim=0).item() \n",
    "        y_pred.extend(batch_pred.cpu().detach().numpy())\n",
    "\n",
    "    print (100 * (num_correct / num_total))\n",
    "    \n",
    "    return true_y, y_pred, num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40074bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Load trained model and run the testing ############\n",
    "\n",
    "model_path = '/home/menglu/123/Deepfake/Top_path_32_512_128_12_8_0.001_epoch_23.pth'\n",
    "eval_output = '/home/menglu/123/Deepfake/built/eval_scores.txt'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "np.random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Parameter\n",
    "config = yaml.safe_load(open('model_config.yaml'))\n",
    "lr = config['lr']\n",
    "warmup = config['warmup']\n",
    "num_epochs = config['epoch']\n",
    "\n",
    "d_model = config['model']['patch_embed']\n",
    "num_filter = config['model']['num_filter']\n",
    "num_block = config['model']['num_block']\n",
    "num_head = config['model']['num_head']\n",
    "\n",
    "# Model Initialization\n",
    "model = Box(config['model'],device).to(device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "\n",
    "# Run the testing\n",
    "if (need_ENF) == True:\n",
    "    true_y, y_pred, num_total = run_testing(evl_set, model, device, eval_output, clf)\n",
    "else:\n",
    "    true_y, y_pred, num_total = run_testing(evl_set, model, device, eval_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Calculate EER for Track1 ############\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(true_y, y_pred, pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "eer = (eer_1 + eer_2) / 2\n",
    "print(eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d607a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Calculate EER for Track2 only ############\n",
    "\n",
    "num = 0\n",
    "for i in range(len(true_y)):\n",
    "    if (true_y[i]==0 and y_pred[i]==1):\n",
    "        num = num+1\n",
    "\n",
    "print(num/num_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
